AWSTemplateFormatVersion: '2010-09-09'
Transform: 'AWS::Serverless-2016-10-31'

Parameters:
  
  RateLimit:
    Type: Number
    Default: 10
    Description: "Requests per second limit"
  BurstLimit:
    Type: Number
    Default: 20
    Description: "Maximum burst requests"
  QuotaLimit:
    Type: Number
    Default: 1000
    Description: "Maximum requests per month"
  QuotaPeriod:
    Type: String
    Default: WEEK
    Description: "Number of requests per Period - DAY | WEEK | MONTH"

Resources:
  # API Gateway
  LLMApi:
    Type: AWS::ApiGateway::RestApi
    Properties:
      Name: LLMRouter
      EndpointConfiguration:
        Types:
          - REGIONAL

  # API Key
  LLMApiKey:
    Type: AWS::ApiGateway::ApiKey
    DependsOn:
      - LLMStage
    Properties:
      Name: LLMApiKey
      Enabled: true
      StageKeys:
        - RestApiId: !Ref LLMApi
          StageName: "prod"

  # Usage Plan
  LLMUsagePlan:
    Type: AWS::ApiGateway::UsagePlan
    Properties:
      UsagePlanName: "LLMProviderUsagePlan"
      ApiStages:
        - ApiId: !Ref LLMApi
          Stage: !Ref LLMStage
      Throttle:
        RateLimit: !Ref RateLimit
        BurstLimit: !Ref BurstLimit
      Quota:
        Limit: !Ref QuotaLimit
        Period: !Ref QuotaPeriod

  UsagePlanKey:
    Type: 'AWS::ApiGateway::UsagePlanKey'
    Properties:
      KeyId: !Ref LLMApiKey
      KeyType: API_KEY
      UsagePlanId: !Ref LLMUsagePlan

  # OpenAI Resource
  OpenAIResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      RestApiId: !Ref LLMApi
      ParentId: !GetAtt LLMApi.RootResourceId
      PathPart: "openai"
  
  OpenAIProxyResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      RestApiId: !Ref LLMApi
      ParentId: !Ref OpenAIResource
      PathPart: "{proxy+}"


  # Anthropic Resource
  AnthropicResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      RestApiId: !Ref LLMApi
      ParentId: !GetAtt LLMApi.RootResourceId
      PathPart: "anthropic"

  AnthropicProxyResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      RestApiId: !Ref LLMApi
      ParentId: !Ref AnthropicResource
      PathPart: "{proxy+}"
  
  # Gemini Resource
  GoogleResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      RestApiId: !Ref LLMApi
      ParentId: !GetAtt LLMApi.RootResourceId
      PathPart: "google"

  GoogleModelResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      RestApiId: !Ref LLMApi
      ParentId: !Ref GoogleResource
      PathPart: "{model+}"

  # OpenAI Method
  OpenAIMethod:
    Type: AWS::ApiGateway::Method
    Properties:
      RestApiId: !Ref LLMApi
      ResourceId: !Ref OpenAIProxyResource
      HttpMethod: POST
      ApiKeyRequired: True
      AuthorizationType: NONE
      Integration:
        IntegrationHttpMethod: POST
        Type: HTTP_PROXY
        Uri: "https://api.openai.com/v1/chat/completions"
        IntegrationResponses:
          - StatusCode: 200
            ResponseTemplates:
              application/json: |
                {
                  "statusCode": 200,
                  "body": $input.body
                }
          - StatusCode: 400
            SelectionPattern: ".*InvalidRequestError.*"
            ResponseTemplates:
              application/json: |
                {
                  "statusCode": 400,
                  "error": "Bad Request",
                  "message": "$input.path('$.error.message')"
                }
          - StatusCode: 401
            SelectionPattern: ".*AuthenticationError.*"
            ResponseTemplates:
              application/json: |
                {
                  "statusCode": 401,
                  "error": "Unauthorized",
                  "message": "$input.path('$.error.message')"
                }
          - StatusCode: 500
            SelectionPattern: ".*ServerError.*"
            ResponseTemplates:
              application/json: |
                {
                  "statusCode": 500,
                  "error": "Internal Server Error",
                  "message": "An error occurred while processing your request."
                }
        PassthroughBehavior: WHEN_NO_MATCH

  # Anthropic Method
  AnthropicMethod:
    Type: AWS::ApiGateway::Method
    Properties:
      RestApiId: !Ref LLMApi
      ResourceId: !Ref AnthropicProxyResource
      HttpMethod: POST
      RequestParameters:
        method.request.header.anthropic-api-key: True
      ApiKeyRequired: True
      AuthorizationType: NONE
      Integration:
        IntegrationHttpMethod: POST
        RequestParameters:
          integration.request.header.x-api-key: method.request.header.anthropic-api-key
        Type: HTTP_PROXY
        Uri: "https://api.anthropic.com/v1/messages"
        IntegrationResponses:
          - StatusCode: 200
        PassthroughBehavior: WHEN_NO_MATCH

  # Google Method
  GoogleMethod:
    Type: AWS::ApiGateway::Method
    Properties:
      RestApiId: !Ref LLMApi
      ResourceId: !Ref GoogleModelResource
      HttpMethod: POST
      ApiKeyRequired: True
      AuthorizationType: NONE
      Integration:
        IntegrationHttpMethod: POST
        Type: HTTP_PROXY
        Uri: "https://generativelanguage.googleapis.com/v1beta/models/{model}"
        IntegrationResponses:
          - StatusCode: 200
        PassthroughBehavior: WHEN_NO_MATCH

  # API Gateway Deployment
  LLMDeployment:
    Type: AWS::ApiGateway::Deployment
    Properties:
      RestApiId: !Ref LLMApi
    DependsOn:
      - OpenAIMethod
      - AnthropicMethod
      - GoogleMethod

  LLMApiGatewayLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub "/aws/apigateway/${LLMApi}"
      RetentionInDays: 7  # Adjust retention period as needed

  # API Gateway Stage with AutoDeploy
  LLMStage:
    Type: AWS::ApiGateway::Stage
    Properties:
      RestApiId: !Ref LLMApi
      StageName: "prod"
      DeploymentId: !Ref LLMDeployment
      MethodSettings:
        - ResourcePath: "/*"
          HttpMethod: "*"
          LoggingLevel: "INFO"  # Set to INFO or ERROR
          DataTraceEnabled: true  # Logs request/response payloads
          MetricsEnabled: true  # Enables CloudWatch metrics

    DependsOn:
      - OpenAIMethod
      - AnthropicMethod
      - GoogleMethod
      - Account
  
  ApiGatewayLoggingRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: 
                - apigateway.amazonaws.com
            Action: 
              - sts:AssumeRole
      ManagedPolicyArns:
      - >-
        arn:aws:iam::aws:policy/service-role/AmazonAPIGatewayPushToCloudWatchLogs

  Account:
    Type: AWS::ApiGateway::Account
    Properties:
      CloudWatchRoleArn: !GetAtt ApiGatewayLoggingRole.Arn

Outputs:
  ApiGatewayInvokeURL:
    Description: "API Gateway endpoint"
    Value: !Sub "https://${LLMApi}.execute-api.${AWS::Region}.amazonaws.com/prod"
  ApiKey:
    Description: "API Key to access the API Gateway"
    Value: !Ref LLMApiKey
    Export:
      Name: "LLMApiKey"
